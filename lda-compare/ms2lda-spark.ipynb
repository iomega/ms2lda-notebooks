{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"mass2lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://slurper.thuis:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mass2lda</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=mass2lda>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Load and parse the data\n",
    "data = sc.textFile(\"spark-2.3.1-bin-hadoop2.7/data/mllib/sample_lda_data.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, DenseVector([1.0, 2.0, 6.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0])],\n",
       " [1, DenseVector([1.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0])],\n",
       " [2, DenseVector([1.0, 4.0, 1.0, 0.0, 0.0, 4.0, 9.0, 0.0, 1.0, 2.0, 0.0])],\n",
       " [3, DenseVector([2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 5.0, 0.0, 2.0, 3.0, 9.0])],\n",
       " [4, DenseVector([3.0, 1.0, 1.0, 9.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0])],\n",
       " [5, DenseVector([4.0, 2.0, 0.0, 3.0, 4.0, 5.0, 1.0, 1.0, 1.0, 4.0, 0.0])],\n",
       " [6, DenseVector([2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 5.0, 0.0, 2.0, 2.0, 9.0])],\n",
       " [7, DenseVector([1.0, 1.0, 1.0, 9.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0])],\n",
       " [8, DenseVector([4.0, 4.0, 0.0, 3.0, 4.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0])],\n",
       " [9, DenseVector([2.0, 8.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 7.0, 2.0])],\n",
       " [10, DenseVector([1.0, 1.0, 1.0, 9.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 3.0])],\n",
       " [11, DenseVector([4.0, 1.0, 0.0, 0.0, 4.0, 5.0, 1.0, 3.0, 0.0, 1.0, 0.0])]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = LDA.train(corpus, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.80911683,  5.92534803, 13.26553513],\n",
       "       [ 7.24924337, 17.0773221 ,  4.67343454],\n",
       "       [ 3.75034495,  2.56833433,  5.68132072],\n",
       "       [ 6.38941297, 17.14583544, 16.46475159],\n",
       "       [ 6.07433555,  4.73043233, 14.19523212],\n",
       "       [ 3.64703307,  2.73534038, 15.61762655],\n",
       "       [11.64292356, 15.13036523,  4.22671121],\n",
       "       [ 1.368516  ,  1.05503843,  7.57644557],\n",
       "       [ 5.22835134,  2.11640909,  0.65523956],\n",
       "       [11.53902065,  9.73173587,  2.72924348],\n",
       "       [22.62038117,  7.86545966,  2.51415917]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaModel.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 11 words):\n",
      "Topic 0:\n",
      " 11.220762185889827\n",
      " 19.929586890740527\n",
      " 7.38745659266717\n",
      " 1.5048994357421388\n",
      " 13.107379966278149\n",
      " 11.712010008136973\n",
      " 6.485715422606812\n",
      " 6.862510383310972\n",
      " 1.604766069074537\n",
      " 7.976274243751031\n",
      " 1.0333503563902324\n",
      "Topic 1:\n",
      " 9.494966954989192\n",
      " 5.02468648800577\n",
      " 2.2027495310373935\n",
      " 12.896192308365976\n",
      " 8.050589711910968\n",
      " 9.038185946650472\n",
      " 15.017624024524089\n",
      " 2.5091200003758347\n",
      " 2.8786421564258666\n",
      " 6.884481439572461\n",
      " 9.593661396705894\n",
      "Topic 2:\n",
      " 5.284270859120981\n",
      " 4.045726621253703\n",
      " 2.409793876295435\n",
      " 25.598908255891885\n",
      " 3.8420303218108836\n",
      " 1.249804045212554\n",
      " 9.496660552869095\n",
      " 0.6283696163131931\n",
      " 3.5165917744995965\n",
      " 9.139244316676509\n",
      " 22.372988246903873\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create a sparse vector, using either a dictionary, a list of\n",
       "(index, value) pairs, or two separate arrays of indices and\n",
       "values (sorted by index).\n",
       "\n",
       ":param size: Size of the vector.\n",
       ":param args: Non-zero entries, as a dictionary, list of tuples,\n",
       "             or two sorted lists containing indices and values.\n",
       "\n",
       ">>> Vectors.sparse(4, {1: 1.0, 3: 5.5})\n",
       "SparseVector(4, {1: 1.0, 3: 5.5})\n",
       ">>> Vectors.sparse(4, [(1, 1.0), (3, 5.5)])\n",
       "SparseVector(4, {1: 1.0, 3: 5.5})\n",
       ">>> Vectors.sparse(4, [1, 3], [1.0, 5.5])\n",
       "SparseVector(4, {1: 1.0, 3: 5.5})\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/spark/python/pyspark/mllib/linalg/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Vectors.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =Vectors.sparse(4, {1: 1.0, 3: 5.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocConcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopicConcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointInterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'em'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Train a LDA model.\n",
       "\n",
       ":param rdd:\n",
       "  RDD of documents, which are tuples of document IDs and term\n",
       "  (word) count vectors. The term count vectors are \"bags of\n",
       "  words\" with a fixed-size vocabulary (where the vocabulary size\n",
       "  is the length of the vector). Document IDs must be unique\n",
       "  and >= 0.\n",
       ":param k:\n",
       "  Number of topics to infer, i.e., the number of soft cluster\n",
       "  centers.\n",
       "  (default: 10)\n",
       ":param maxIterations:\n",
       "  Maximum number of iterations allowed.\n",
       "  (default: 20)\n",
       ":param docConcentration:\n",
       "  Concentration parameter (commonly named \"alpha\") for the prior\n",
       "  placed on documents' distributions over topics (\"theta\").\n",
       "  (default: -1.0)\n",
       ":param topicConcentration:\n",
       "  Concentration parameter (commonly named \"beta\" or \"eta\") for\n",
       "  the prior placed on topics' distributions over terms.\n",
       "  (default: -1.0)\n",
       ":param seed:\n",
       "  Random seed for cluster initialization. Set as None to generate\n",
       "  seed based on system time.\n",
       "  (default: None)\n",
       ":param checkpointInterval:\n",
       "  Period (in iterations) between checkpoints.\n",
       "  (default: 10)\n",
       ":param optimizer:\n",
       "  LDAOptimizer used to perform the actual calculation. Currently\n",
       "  \"em\", \"online\" are supported.\n",
       "  (default: \"em\")\n",
       "\n",
       ".. versionadded:: 1.5.0\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/spark/python/pyspark/mllib/clustering.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LDA.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vectors.dense([1.0, 2.0, 6.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create a sparse vector, using either a dictionary, a list of\n",
       "(index, value) pairs, or two separate arrays of indices and\n",
       "values (sorted by index).\n",
       "\n",
       ":param size: Size of the vector.\n",
       ":param args: Non-zero entries, as a dictionary, list of tuples,\n",
       "             or two sorted lists containing indices and values.\n",
       "\n",
       ">>> Vectors.sparse(4, {1: 1.0, 3: 5.5})\n",
       "SparseVector(4, {1: 1.0, 3: 5.5})\n",
       ">>> Vectors.sparse(4, [(1, 1.0), (3, 5.5)])\n",
       "SparseVector(4, {1: 1.0, 3: 5.5})\n",
       ">>> Vectors.sparse(4, [1, 3], [1.0, 5.5])\n",
       "SparseVector(4, {1: 1.0, 3: 5.5})\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/spark/python/pyspark/mllib/linalg/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Vectors.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
